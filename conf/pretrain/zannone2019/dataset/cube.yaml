dataset_artifact_name: "cube_split_1:tmp"
batch_size: 128
epochs: 2000
limit_train_batches: null
limit_val_batches: null

lr: 1e-3
min_masking_probability: 0.0
max_masking_probability: 0.9
pointnet:
  type: "pointnetplus" # ODIN paper does not mention which type they use
  # identity_network_num_cells: [128,128]
  # identity_network_num_cells: [] # EDDI
  # identity_network_dropout: 0.1
  # identity_size: 128
  identity_size: 20 # EDDI
  # feature_map_encoder_num_cells: [128,128]
  feature_map_encoder_num_cells: [500] # EDDI
  feature_map_encoder_dropout: 0.1
  output_size: 128 # always twice as large as latent size according to EDDI paper
encoder:
  # num_cells: [128, 128]
  num_cells: [500, 500, 200]
  dropout: 0.1
partial_vae:
  latent_size: 64
  # decoder_num_cells: [128, 128]
  decoder_num_cells: [200, 500, 500] # EDDI
  decoder_dropout: 0.1
classifier:
  num_cells: [128, 128]
  dropout: 0.1
recon_loss_type: "squared_error"
kl_scaling_factor: 0.01
classifier_loss_scaling_factor: 10
