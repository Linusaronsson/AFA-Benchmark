# reward_method set in higher config
pq_module:
  n_hiddens: [512,512,128,64] # kachuee2019 implementation for MNIST
  p_dropout: 0.5 # kachuee2019 implementation
mcdrop_samples: 100 # kachuee2019 implementation

dataset_artifact_name: "MNIST_split_1:tmp"
# n_agents: 1 # kachuee2019 implementation
n_agents: 2 # same as shim2018
hard_budget: 30 # recommended: 10, 20, 30
agent:
  eps_init: 1.0 # kachuee2019 implementation
  eps_end: 0.1 # kachuee2019 implementation
  # eps_annealing_num_batches: 30000 # kachuee2019 implementation, same as `n_batches`
  eps_annealing_num_batches: 60000 # same as `n_batches`

  replay_buffer_batch_size: 128 # kachuee2019 implementation
  # replay_buffer_batch_size: 16
  replay_buffer_size: 30000 # kachuee2019 paper, 1000*n_features

  num_optim: 1 # kachuee2019 implementation
  max_action_value_grad_norm: 9001 # not specified by kachuee2019 implementation
  action_value_lr: 1e-3 # kachuee2019 implementation
  update_tau: 0.001 # kachuee2019 implementation
  max_classification_grad_norm: 9001 # not specified by kachuee2019 implementation
  classification_lr: 1e-3 # kachuee2019 implementation

  loss_function: "l2" # kachuee2019 implementation
  delay_value: true # kachuee2019 implementation
  double_dqn: true # kachuee2019 implementation

  # gamma set by higher config
# n_batches: 30000 # kachuee2019 implementation, 1000 episodes
n_batches: 60000 # needed for convergence
# batch_size: 1 # kachuee2019 implementation
batch_size: 64 # same as shim2018
# eval_every_n_batches: 3000 # kachuee2019 implementation, every 100 episodes
eval_every_n_batches: 500
eval_max_steps: 9001
# n_eval_episodes: 512 # kachuee2019 implementation
n_eval_episodes: 100
# device set by higher config
# seed set by higher config
# output_artifact_aliases set by higher config
evaluate_final_performance: true
eval_only_n_samples: 100
