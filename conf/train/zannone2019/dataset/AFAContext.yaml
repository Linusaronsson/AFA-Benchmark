pretrained_model_artifact_name: "pretrain_zannone2019-AFAContext_split_1:tmp"
n_agents: 128 # same as shim2018
hard_budget: 5 # recommended: 3, 5, 10
agent:
  # gamma set by higher config
  lmbda: 0.75 # not specified by zannone2019, same as shim2018

  clip_epsilon: 0.2 # not specified by zannone2019
  # entropy_bonus: True # not specified by zannone2019
  entropy_bonus: False # not specified by zannone2019
  # entropy_coef: 0.01 # not specified by zannone2019
  entropy_coef: 0.0 # not specified by zannone2019
  critic_coef: 1.0 # not specified by zannone2019
  loss_critic_type: "smooth_l1" # not specified by zannone2019

  num_epochs: 1 # same as shim2018
  lr: 1e-3 # not specified by zannone2019
  max_grad_norm: 9001 # not specified by zannone2019
  replay_buffer_batch_size: 128 # same as shim2018

  value_num_cells: [32, 32] # had to be increased from [] to work on this dataset
  value_dropout: 0.0 # not specified by zannone2019
  policy_num_cells: [32, 32] # had to be increased from [] to work on this dataset
  policy_dropout: 0.0 # not specified by zannone2019
n_batches: 200000 # AFAContext is treated specially
batch_size: 512 # same as shim2018
eval_every_n_batches: 500
eval_max_steps: 9001
n_eval_episodes: 100
# n_generated_samples: 10000 # ODIN paper
n_generated_samples: 0
generation_batch_size: 100
evaluate_final_performance: true
eval_only_n_samples: null
