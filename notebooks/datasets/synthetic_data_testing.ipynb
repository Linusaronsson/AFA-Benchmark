{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Cube dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CubeDataset.__init__() got an unexpected keyword argument 'informative_feature_variance'. Did you mean 'informative_feature_std'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Generate the Cube dataset\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating Cube dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m dataset = \u001b[43mCubeDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced for faster execution\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnon_informative_feature_mean\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43minformative_feature_variance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnon_informative_feature_variance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m dataset.generate_data()\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Get features and labels\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: CubeDataset.__init__() got an unexpected keyword argument 'informative_feature_variance'. Did you mean 'informative_feature_std'?"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import CubeDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the Cube dataset\n",
    "print(\"Generating Cube dataset...\")\n",
    "dataset = CubeDataset(\n",
    "    n_features=20,\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    informative_feature_variance=0.2,\n",
    "    non_informative_feature_variance=0.3\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Train a random forest classifier\n",
    "print(\"\\nTraining Random Forest classifier...\")\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AFAContext dataset...\n",
      "Dataset shape: torch.Size([1000, 30])\n",
      "Number of classes: 8\n",
      "Class distribution: tensor([111, 110, 156, 129, 129, 118, 109, 138])\n",
      "Train set shape: (800, 30)\n",
      "Test set shape: (200, 30)\n",
      "\n",
      "Training Random Forest classifier on first 10 features...\n",
      "Test accuracy: 0.9900\n",
      "\n",
      "Training Random Forest classifier on next 10 features...\n",
      "Test accuracy: 0.7950\n",
      "\n",
      "Training Random Forest classifier on all features...\n",
      "Test accuracy: 0.9050\n",
      "\n",
      "Training Random Forest classifier on all features except first 10...\n",
      "Test accuracy: 0.8350\n",
      "\n",
      "Training Random Forest classifier on all features except second 10...\n",
      "Test accuracy: 0.9600\n",
      "\n",
      "Accuracy Comparison:\n",
      "First 10 features: 0.9900\n",
      "Next 10 features: 0.7950\n",
      "All features: 0.9050\n",
      "All features except first 10: 0.8350\n",
      "All features except second 10: 0.9600\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import AFAContextDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 49\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the AFAContext dataset\n",
    "print(\"Generating AFAContext dataset...\")\n",
    "dataset = AFAContextDataset(\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    sigma_bin=0.1,\n",
    "    sigma_cube=0.3,\n",
    "    bin_feature_cost=5.0,\n",
    "    n_dummy_features=10,\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    non_informative_feature_variance=0.3\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Function to train and evaluate a random forest on a subset of features\n",
    "def train_and_evaluate_rf(X_train, X_test, y_train, y_test, feature_indices, description):\n",
    "    print(f\"\\nTraining Random Forest classifier on {description}...\")\n",
    "    \n",
    "    # Select features\n",
    "    X_train_subset = X_train[:, feature_indices]\n",
    "    X_test_subset = X_test[:, feature_indices]\n",
    "    \n",
    "    # Train a random forest classifier\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "    rf_classifier.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_classifier.predict(X_test_subset)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# 1. Train on first 10 features\n",
    "first_10_features = list(range(10))\n",
    "first_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    first_10_features, \n",
    "    \"first 10 features\"\n",
    ")\n",
    "\n",
    "# 2. Train on next 10 features\n",
    "next_10_features = list(range(10, 20))\n",
    "next_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    next_10_features, \n",
    "    \"next 10 features\"\n",
    ")\n",
    "\n",
    "# 3. Train on all features\n",
    "all_features = list(range(X.shape[1]))\n",
    "all_features_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    all_features, \n",
    "    \"all features\"\n",
    ")\n",
    "\n",
    "# 4. Train on all features EXCEPT the first 10\n",
    "all_except_first_10 = list(range(10, X.shape[1]))\n",
    "all_except_first_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    all_except_first_10, \n",
    "    \"all features except first 10\"\n",
    ")\n",
    "\n",
    "# 5. Train on all features EXCEPT the second 10\n",
    "all_except_second_10 = list(range(0, 10)) + list(range(20, X.shape[1]))\n",
    "all_except_second_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, \n",
    "    all_except_second_10, \n",
    "    \"all features except second 10\"\n",
    ")\n",
    "\n",
    "# Compare accuracies\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "print(f\"First 10 features: {first_10_accuracy:.4f}\")\n",
    "print(f\"Next 10 features: {next_10_accuracy:.4f}\")\n",
    "print(f\"All features: {all_features_accuracy:.4f}\")\n",
    "print(f\"All features except first 10: {all_except_first_10_accuracy:.4f}\")\n",
    "print(f\"All features except second 10: {all_except_second_10_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.        ,  0.700197  ,  0.35703996, -0.00740662,  0.35492504,\n",
       "       -0.27242595,  0.19037262, -0.01277946,  0.96048504, -0.10163771,\n",
       "        0.77107656,  0.25822085, -0.33570838,  0.8615771 ,  0.14473464,\n",
       "        0.4954611 ,  0.64497924,  1.0047779 ,  0.6330979 ,  0.6313545 ,\n",
       "        0.4355412 ,  0.48715666,  0.7985137 ,  0.57150555,  0.5015381 ,\n",
       "        0.13134798,  0.28174898,  0.6638046 ,  0.7241597 ,  0.62216496],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from common.custom_types import FeatureMask, MaskedFeatures, Features, Label\n",
    "class AFAContextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset merging AFA structure with cube-dataset dummy-feature behavior.\n",
    "\n",
    "    Implements the AFADataset protocol.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_samples: int = 1000,\n",
    "        sigma_bin: float = 0.1,\n",
    "        sigma_cube: float = 1.0,\n",
    "        bin_feature_cost: float = 5.0,\n",
    "        n_dummy_features: int = 10,\n",
    "        seed: int = 123,\n",
    "        non_informative_feature_mean: float = 0.5,\n",
    "        non_informative_feature_variance: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.sigma_bin = sigma_bin\n",
    "        self.sigma_cube = sigma_cube\n",
    "        self.bin_feature_cost = bin_feature_cost\n",
    "        self.n_dummy_features = n_dummy_features\n",
    "        self.seed = seed\n",
    "        self.non_info_mean = non_informative_feature_mean\n",
    "        self.non_info_std = math.sqrt(non_informative_feature_variance)\n",
    "\n",
    "        # Constants\n",
    "        self.n_classes = 8\n",
    "        self.n_context_groups = 3\n",
    "        self.group_size = 3\n",
    "        self.n_bin_features = self.n_context_groups * self.group_size\n",
    "        self.n_cube_features = 10\n",
    "\n",
    "        # Placeholder attributes\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "        self.costs = None\n",
    "        self.feature_names = None\n",
    "\n",
    "        # Generate upon initialization\n",
    "        self.generate_data()\n",
    "\n",
    "    def generate_data(self) -> None:\n",
    "        rng = torch.Generator()\n",
    "        rng.manual_seed(self.seed)\n",
    "\n",
    "        # Draw labels and context\n",
    "        y_int = torch.randint(0, self.n_classes, (self.n_samples,), dtype=torch.int64, generator=rng)\n",
    "        S = torch.randint(0, self.n_context_groups, (self.n_samples,), dtype=torch.int64, generator=rng)\n",
    "\n",
    "        # Binary codes for labels (8×3)\n",
    "        binary_codes = torch.stack([\n",
    "            torch.tensor([int(b) for b in format(i, '03b')], dtype=torch.float32)\n",
    "            for i in range(self.n_classes)\n",
    "        ], dim=0)\n",
    "\n",
    "        # Initialize feature blocks\n",
    "        X_context = S.unsqueeze(1).float()\n",
    "\n",
    "        X_bin = torch.normal(\n",
    "            mean=self.non_info_mean,\n",
    "            std=self.non_info_std,\n",
    "            size=(self.n_samples, self.n_bin_features),\n",
    "            generator=rng,\n",
    "        )\n",
    "\n",
    "        X_cube = torch.normal(\n",
    "            mean=self.non_info_mean,\n",
    "            std=self.non_info_std,\n",
    "            size=(self.n_samples, self.n_cube_features),\n",
    "            generator=rng,\n",
    "        )\n",
    "\n",
    "        X_dummy = torch.normal(\n",
    "            mean=self.non_info_mean,\n",
    "            std=self.non_info_std,\n",
    "            size=(self.n_samples, self.n_dummy_features),\n",
    "            generator=rng,\n",
    "        )\n",
    "\n",
    "        # Insert informative signals\n",
    "        for i in range(self.n_samples):\n",
    "            lbl = y_int[i].item()\n",
    "            ctx = S[i].item()\n",
    "            mu_bin = binary_codes[lbl]\n",
    "\n",
    "            # Binary features in active group\n",
    "            start = ctx * self.group_size\n",
    "            end = start + self.group_size\n",
    "            X_bin[i, start:end] = torch.normal(\n",
    "                mean=0.0,\n",
    "                std=self.sigma_bin,\n",
    "                size=(self.group_size,),\n",
    "                generator=rng\n",
    "            ) + mu_bin\n",
    "\n",
    "            # Cube features: 3 bumps\n",
    "            idxs = [(lbl + j) % self.n_cube_features for j in range(3)]\n",
    "            X_cube[i, idxs] = torch.normal(\n",
    "                mean=0.0,\n",
    "                std=self.sigma_cube,\n",
    "                size=(3,),\n",
    "                generator=rng\n",
    "            ) + mu_bin\n",
    "\n",
    "        # Concatenate all features\n",
    "        self.features = torch.cat([X_context, X_bin, X_cube, X_dummy], dim=1)\n",
    "\n",
    "        # Build costs vector\n",
    "        total_dim = self.features.shape[1]\n",
    "        costs = torch.ones(total_dim)\n",
    "        costs[1:1 + self.n_bin_features] = self.bin_feature_cost\n",
    "        self.costs = costs\n",
    "\n",
    "        # One-hot labels\n",
    "        #self.labels = torch.nn.functional.one_hot(y_int, num_classes=self.n_classes).float()\n",
    "        self.labels = y_int\n",
    "\n",
    "        # Feature names\n",
    "        names = ['context']\n",
    "        names += [f'bin_{i}' for i in range(self.n_bin_features)]\n",
    "        names += [f'cube_{i}' for i in range(self.n_cube_features)]\n",
    "        names += [f'dummy_{i}' for i in range(self.n_dummy_features)]\n",
    "        self.feature_names = names\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.size(0)\n",
    "\n",
    "    def get_all_data(self):\n",
    "        return self.features, self.labels\n",
    "\n",
    "    def save(self, path: str) -> None:\n",
    "        torch.save(\n",
    "            {\n",
    "                'features': self.features,\n",
    "                'labels': self.labels,\n",
    "                'costs': self.costs,\n",
    "                'feature_names': self.feature_names,\n",
    "                'config': {\n",
    "                    'n_samples': self.n_samples,\n",
    "                    'sigma_bin': self.sigma_bin,\n",
    "                    'sigma_cube': self.sigma_cube,\n",
    "                    'bin_feature_cost': self.bin_feature_cost,\n",
    "                    'n_dummy_features': self.n_dummy_features,\n",
    "                    'seed': self.seed,\n",
    "                    'non_informative_feature_mean': self.non_info_mean,\n",
    "                    'non_informative_feature_variance': self.non_info_std ** 2,\n",
    "                },\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path: str) -> 'AFAContextDataset':\n",
    "        data = torch.load(path)\n",
    "        cfg = data['config']\n",
    "        ds = AFAContextDataset(**cfg)\n",
    "        ds.features = data['features']\n",
    "        ds.labels = data['labels']\n",
    "        ds.costs = data['costs']\n",
    "        ds.feature_names = data['feature_names']\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AFAContext dataset...\n",
      "torch.Size([8, 3])\n",
      "torch.Size([8, 3])\n",
      "Dataset shape: torch.Size([1000, 30])\n",
      "Number of classes: 8\n",
      "Class distribution: tensor([133, 117, 113, 146, 125, 113, 119, 134])\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the AFAContext dataset\n",
    "print(\"Generating AFAContext dataset...\")\n",
    "dataset = AFAContextDataset(\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    sigma_bin=0.1,\n",
    "    sigma_cube=1.0,\n",
    "    bin_feature_cost=5.0,\n",
    "    n_dummy_features=10,\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    non_informative_feature_variance=0.3\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Cube dataset...\n",
      "Dataset shape: torch.Size([1000, 20])\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import CubeDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the Cube dataset\n",
    "print(\"Generating Cube dataset...\")\n",
    "dataset = CubeDataset(\n",
    "    n_features=20,\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    non_informative_feature_std=0,\n",
    "    informative_feature_std=0\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "#print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 6, 2, 7, 4, 4, 6, 1, 2, 6, 2, 2, 7, 4, 3, 7, 7, 2, 5, 4,\n",
       "       1, 7, 3, 5, 5, 1, 7, 3, 4, 0, 3, 1, 5, 4, 3, 0, 0, 2, 2, 6, 1, 7,\n",
       "       3, 3, 7, 6, 5, 5, 6, 5, 2, 3, 6, 3, 7, 0, 2, 4, 2, 6, 4, 0, 6, 1,\n",
       "       3, 0, 3, 5, 1, 1, 0, 1, 4, 1, 3, 3, 6, 3, 6, 3, 4, 7, 6, 2, 5, 0,\n",
       "       3, 1, 7, 3, 1, 5, 5, 5, 1, 3, 5, 4, 6, 1, 1, 3, 1, 1, 5, 3, 5, 6,\n",
       "       7, 6, 7, 5, 6, 3, 0, 5, 7, 4, 7, 4, 1, 6, 4, 7, 1, 0, 3, 3, 3, 4,\n",
       "       0, 4, 6, 4, 0, 0, 6, 0, 7, 0, 3, 7, 7, 6, 2, 2, 0, 7, 2, 2, 0, 2,\n",
       "       4, 1, 6, 1, 0, 3, 6, 0, 7, 3, 1, 0, 7, 6, 6, 5, 7, 4, 2, 3, 7, 5,\n",
       "       2, 2, 0, 2, 4, 6, 5, 2, 0, 4, 1, 6, 6, 5, 6, 2, 0, 6, 6, 1, 1, 3,\n",
       "       4, 2, 6, 7, 6, 0, 3, 4, 7, 3, 5, 4, 6, 6, 4, 6, 2, 4, 3, 4, 7, 6,\n",
       "       2, 2, 5, 3, 1, 1, 4, 5, 0, 4, 5, 3, 3, 3, 3, 3, 5, 5, 2, 7, 1, 6,\n",
       "       3, 0, 6, 5, 0, 0, 0, 2, 5, 0, 3, 4, 0, 2, 6, 5, 7, 2, 0, 5, 4, 0,\n",
       "       2, 1, 3, 7, 6, 2, 5, 7, 7, 7, 0, 3, 0, 5, 0, 1, 3, 3, 5, 6, 1, 2,\n",
       "       0, 4, 0, 7, 0, 2, 0, 1, 1, 3, 5, 6, 4, 7, 0, 0, 2, 5, 1, 4, 3, 1,\n",
       "       7, 5, 7, 6, 3, 6, 2, 7, 2, 0, 6, 5, 7, 4, 3, 1, 5, 5, 2, 6, 7, 7,\n",
       "       0, 0, 3, 2, 5, 7, 4, 2, 3, 3, 2, 3, 2, 1, 2, 6, 2, 3, 7, 6, 3, 0,\n",
       "       0, 7, 7, 6, 1, 7, 0, 2, 3, 0, 0, 1, 6, 6, 5, 1, 2, 6, 3, 7, 1, 7,\n",
       "       0, 3, 3, 0, 1, 0, 7, 5, 3, 4, 4, 7, 2, 6, 0, 0, 2, 2, 7, 7, 2, 3,\n",
       "       7, 5, 7, 0, 7, 3, 2, 0, 7, 3, 5, 7, 3, 5, 2, 7, 5, 0, 2, 0, 4, 1,\n",
       "       7, 5, 1, 1, 5, 2, 7, 4, 0, 3, 0, 3, 0, 5, 4, 7, 3, 7, 7, 7, 6, 2,\n",
       "       0, 7, 0, 7, 3, 2, 2, 5, 6, 5, 5, 5, 5, 5, 4, 2, 5, 7, 2, 2, 1, 4,\n",
       "       5, 0, 3, 6, 7, 0, 4, 3, 4, 7, 2, 3, 2, 7, 0, 7, 0, 3, 3, 5, 4, 5,\n",
       "       4, 5, 2, 3, 0, 4, 7, 4, 0, 5, 4, 6, 2, 3, 0, 3, 6, 4, 4, 7, 6, 0,\n",
       "       7, 2, 7, 1, 0, 1, 6, 5, 1, 2, 7, 5, 7, 1, 7, 6, 5, 6, 1, 6, 2, 1,\n",
       "       1, 1, 0, 7, 0, 0, 2, 5, 7, 6, 4, 1, 6, 1, 2, 1, 0, 7, 4, 3, 1, 6,\n",
       "       0, 3, 4, 3, 0, 7, 7, 5, 7, 5, 3, 2, 6, 6, 3, 1, 1, 7, 6, 6, 5, 2,\n",
       "       0, 1, 6, 5, 4, 5, 1, 1, 5, 0, 3, 1, 5, 6, 5, 2, 3, 4, 0, 7, 4, 3,\n",
       "       3, 3, 4, 6, 3, 5, 4, 7, 3, 5, 6, 2, 6, 7, 3, 7, 4, 1, 3, 1, 5, 2,\n",
       "       0, 7, 6, 2, 3, 1, 6, 1, 4, 1, 4, 5, 6, 6, 0, 3, 4, 0, 1, 1, 0, 6,\n",
       "       1, 7, 5, 5, 7, 0, 7, 4, 4, 0, 7, 4, 6, 7, 6, 4, 5, 4, 6, 2, 3, 1,\n",
       "       7, 2, 4, 5, 0, 4, 5, 3, 4, 6, 0, 5, 5, 5, 3, 4, 3, 7, 1, 1, 7, 4,\n",
       "       6, 3, 0, 5, 5, 4, 6, 1, 1, 5, 4, 3, 1, 3, 6, 1, 1, 2, 1, 7, 0, 7,\n",
       "       4, 4, 3, 7, 7, 7, 6, 1, 0, 3, 7, 7, 2, 3, 7, 3, 1, 2, 3, 0, 0, 4,\n",
       "       2, 2, 4, 3, 2, 0, 0, 7, 1, 2, 3, 4, 4, 3, 6, 5, 1, 4, 2, 1, 2, 6,\n",
       "       0, 1, 7, 4, 1, 1, 1, 5, 1, 2, 0, 6, 3, 1, 4, 1, 4, 2, 4, 7, 3, 0,\n",
       "       4, 4, 0, 3, 1, 4, 0, 7, 7, 2, 0, 2, 7, 3, 1, 0, 6, 7, 7, 6, 5, 7,\n",
       "       4, 3, 0, 6, 4, 6, 0, 2, 0, 5, 0, 0, 5, 3, 7, 0, 5, 4, 2, 2, 0, 3,\n",
       "       3, 4, 0, 2, 3, 0, 6, 3, 5, 6, 7, 3, 2, 1, 6, 7, 4, 4, 2, 3, 0, 3,\n",
       "       2, 4, 3, 4, 6, 7, 0, 6, 4, 4, 1, 1, 6, 5, 6, 1, 4, 2, 6, 4, 2, 2,\n",
       "       1, 6, 3, 0, 1, 1, 3, 0, 4, 5, 6, 5, 4, 7, 1, 0, 1, 2, 1, 1, 4, 4,\n",
       "       4, 5, 2, 7, 7, 4, 0, 5, 3, 0, 6, 6, 0, 4, 3, 3, 5, 3, 6, 2, 4, 3,\n",
       "       5, 6, 2, 1, 1, 2, 6, 5, 2, 4, 4, 1, 3, 5, 1, 3, 3, 7, 4, 6, 0, 6,\n",
       "       0, 2, 4, 3, 5, 0, 6, 3, 0, 0, 7, 0, 5, 4, 5, 1, 3, 4, 7, 4, 4, 6,\n",
       "       4, 7, 5, 4, 2, 3, 4, 3, 2, 2, 3, 0, 1, 6, 0, 0, 5, 6, 6, 0, 4, 5,\n",
       "       5, 2, 7, 6, 0, 2, 3, 1, 7, 7, 7, 5, 3, 7, 3, 4, 7, 1, 3, 3, 1, 7,\n",
       "       1, 3, 1, 3, 3, 4, 0, 3, 7, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(7),\n",
       " array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1. , 1. , 1. , 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "np.argmax(y[i]), X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary codes for labels (8×3)\n",
    "binary_codes = torch.stack([\n",
    "    torch.tensor([int(b) for b in format(i, '03b')])\n",
    "    for i in range(8)\n",
    "], dim=0)\n",
    "binary_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(1),\n",
       " array([0.5, 1. , 0. , 0. , 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 9\n",
    "np.argmax(y[i]), X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "binary_codes = torch.stack([\n",
    "    torch.tensor([int(b) for b in format(i, '03b')])\n",
    "    for i in range(8)\n",
    "], dim=0).flip(-1)        # <-- reverse bit order in-place\n",
    "\n",
    "print(binary_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
