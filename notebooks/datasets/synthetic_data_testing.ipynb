{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import CubeDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the Cube dataset\n",
    "print(\"Generating Cube dataset...\")\n",
    "dataset = CubeDataset(\n",
    "    n_features=20,\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    informative_feature_variance=0.2,\n",
    "    non_informative_feature_variance=0.3,\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Train a random forest classifier\n",
    "print(\"\\nTraining Random Forest classifier...\")\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    ")\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130064, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"../../datasets/miniboone.csv\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([93565, 36499]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../../datasets/miniboone.csv\")\n",
    "np.unique(df[\"Outcome\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AFAContext dataset...\n",
      "Dataset shape: torch.Size([1000, 30])\n",
      "class distr  (array([0, 1, 2, 3, 4, 5, 6, 7]), array([111, 110, 156, 129, 129, 118, 109, 138]))\n",
      "Train set shape: (800, 30)\n",
      "Test set shape: (200, 30)\n",
      "\n",
      "Training Random Forest classifier on first 10 features...\n",
      "Test accuracy: 1.0000\n",
      "\n",
      "Training Random Forest classifier on next 10 features...\n",
      "Test accuracy: 0.7950\n",
      "\n",
      "Training Random Forest classifier on all features...\n",
      "Test accuracy: 0.9300\n",
      "\n",
      "Training Random Forest classifier on all features except first 10...\n",
      "Test accuracy: 0.8000\n",
      "\n",
      "Training Random Forest classifier on all features except second 10...\n",
      "Test accuracy: 0.9900\n",
      "\n",
      "Accuracy Comparison:\n",
      "First 10 features: 1.0000\n",
      "Next 10 features: 0.7950\n",
      "All features: 0.9300\n",
      "All features except first 10: 0.8000\n",
      "All features except second 10: 0.9900\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import AFAContextDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 49\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the AFAContext dataset\n",
    "print(\"Generating AFAContext dataset...\")\n",
    "dataset = AFAContextDataset(\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    std_bin=0.1,\n",
    "    std_cube=0.3,\n",
    "    bin_feature_cost=5.0,\n",
    "    n_dummy_features=10,\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    non_informative_feature_std=0.3,\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(\"class distr \", np.unique(y, return_counts=True))\n",
    "\n",
    "\n",
    "# Split into train and test sets (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# Function to train and evaluate a random forest on a subset of features\n",
    "def train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, feature_indices, description\n",
    "):\n",
    "    print(f\"\\nTraining Random Forest classifier on {description}...\")\n",
    "\n",
    "    # Select features\n",
    "    X_train_subset = X_train[:, feature_indices]\n",
    "    X_test_subset = X_test[:, feature_indices]\n",
    "\n",
    "    # Train a random forest classifier\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "    )\n",
    "    rf_classifier.fit(X_train_subset, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_classifier.predict(X_test_subset)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 1. Train on first 10 features\n",
    "first_10_features = list(range(10))\n",
    "first_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, first_10_features, \"first 10 features\"\n",
    ")\n",
    "\n",
    "# 2. Train on next 10 features\n",
    "next_10_features = list(range(10, 20))\n",
    "next_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, next_10_features, \"next 10 features\"\n",
    ")\n",
    "\n",
    "# 3. Train on all features\n",
    "all_features = list(range(X.shape[1]))\n",
    "all_features_accuracy = train_and_evaluate_rf(\n",
    "    X_train, X_test, y_train, y_test, all_features, \"all features\"\n",
    ")\n",
    "\n",
    "# 4. Train on all features EXCEPT the first 10\n",
    "all_except_first_10 = list(range(10, X.shape[1]))\n",
    "all_except_first_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    all_except_first_10,\n",
    "    \"all features except first 10\",\n",
    ")\n",
    "\n",
    "# 5. Train on all features EXCEPT the second 10\n",
    "all_except_second_10 = list(range(10)) + list(range(20, X.shape[1]))\n",
    "all_except_second_10_accuracy = train_and_evaluate_rf(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    all_except_second_10,\n",
    "    \"all features except second 10\",\n",
    ")\n",
    "\n",
    "# Compare accuracies\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "print(f\"First 10 features: {first_10_accuracy:.4f}\")\n",
    "print(f\"Next 10 features: {next_10_accuracy:.4f}\")\n",
    "print(f\"All features: {all_features_accuracy:.4f}\")\n",
    "print(f\"All features except first 10: {all_except_first_10_accuracy:.4f}\")\n",
    "print(f\"All features except second 10: {all_except_second_10_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Cube dataset...\n",
      "Dataset shape: torch.Size([1000, 20])\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Add the src directory to the path to import from common\n",
    "from common.datasets import CubeDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate the Cube dataset\n",
    "print(\"Generating Cube dataset...\")\n",
    "dataset = CubeDataset(\n",
    "    n_features=20,\n",
    "    n_samples=1000,  # Reduced for faster execution\n",
    "    seed=SEED,\n",
    "    non_informative_feature_mean=0.5,\n",
    "    non_informative_feature_std=0,\n",
    "    informative_feature_std=0,\n",
    ")\n",
    "dataset.generate_data()\n",
    "\n",
    "# Get features and labels\n",
    "features, labels = dataset.get_all_data()\n",
    "print(f\"Dataset shape: {features.shape}\")\n",
    "print(f\"Number of classes: {len(torch.unique(labels))}\")\n",
    "# print(f\"Class distribution: {torch.bincount(labels.long(), minlength=8)}\")\n",
    "\n",
    "# Convert to numpy for scikit-learn\n",
    "X = features.numpy()\n",
    "y = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 6, 2, 7, 4, 4, 6, 1, 2, 6, 2, 2, 7, 4, 3, 7, 7, 2, 5, 4,\n",
       "       1, 7, 3, 5, 5, 1, 7, 3, 4, 0, 3, 1, 5, 4, 3, 0, 0, 2, 2, 6, 1, 7,\n",
       "       3, 3, 7, 6, 5, 5, 6, 5, 2, 3, 6, 3, 7, 0, 2, 4, 2, 6, 4, 0, 6, 1,\n",
       "       3, 0, 3, 5, 1, 1, 0, 1, 4, 1, 3, 3, 6, 3, 6, 3, 4, 7, 6, 2, 5, 0,\n",
       "       3, 1, 7, 3, 1, 5, 5, 5, 1, 3, 5, 4, 6, 1, 1, 3, 1, 1, 5, 3, 5, 6,\n",
       "       7, 6, 7, 5, 6, 3, 0, 5, 7, 4, 7, 4, 1, 6, 4, 7, 1, 0, 3, 3, 3, 4,\n",
       "       0, 4, 6, 4, 0, 0, 6, 0, 7, 0, 3, 7, 7, 6, 2, 2, 0, 7, 2, 2, 0, 2,\n",
       "       4, 1, 6, 1, 0, 3, 6, 0, 7, 3, 1, 0, 7, 6, 6, 5, 7, 4, 2, 3, 7, 5,\n",
       "       2, 2, 0, 2, 4, 6, 5, 2, 0, 4, 1, 6, 6, 5, 6, 2, 0, 6, 6, 1, 1, 3,\n",
       "       4, 2, 6, 7, 6, 0, 3, 4, 7, 3, 5, 4, 6, 6, 4, 6, 2, 4, 3, 4, 7, 6,\n",
       "       2, 2, 5, 3, 1, 1, 4, 5, 0, 4, 5, 3, 3, 3, 3, 3, 5, 5, 2, 7, 1, 6,\n",
       "       3, 0, 6, 5, 0, 0, 0, 2, 5, 0, 3, 4, 0, 2, 6, 5, 7, 2, 0, 5, 4, 0,\n",
       "       2, 1, 3, 7, 6, 2, 5, 7, 7, 7, 0, 3, 0, 5, 0, 1, 3, 3, 5, 6, 1, 2,\n",
       "       0, 4, 0, 7, 0, 2, 0, 1, 1, 3, 5, 6, 4, 7, 0, 0, 2, 5, 1, 4, 3, 1,\n",
       "       7, 5, 7, 6, 3, 6, 2, 7, 2, 0, 6, 5, 7, 4, 3, 1, 5, 5, 2, 6, 7, 7,\n",
       "       0, 0, 3, 2, 5, 7, 4, 2, 3, 3, 2, 3, 2, 1, 2, 6, 2, 3, 7, 6, 3, 0,\n",
       "       0, 7, 7, 6, 1, 7, 0, 2, 3, 0, 0, 1, 6, 6, 5, 1, 2, 6, 3, 7, 1, 7,\n",
       "       0, 3, 3, 0, 1, 0, 7, 5, 3, 4, 4, 7, 2, 6, 0, 0, 2, 2, 7, 7, 2, 3,\n",
       "       7, 5, 7, 0, 7, 3, 2, 0, 7, 3, 5, 7, 3, 5, 2, 7, 5, 0, 2, 0, 4, 1,\n",
       "       7, 5, 1, 1, 5, 2, 7, 4, 0, 3, 0, 3, 0, 5, 4, 7, 3, 7, 7, 7, 6, 2,\n",
       "       0, 7, 0, 7, 3, 2, 2, 5, 6, 5, 5, 5, 5, 5, 4, 2, 5, 7, 2, 2, 1, 4,\n",
       "       5, 0, 3, 6, 7, 0, 4, 3, 4, 7, 2, 3, 2, 7, 0, 7, 0, 3, 3, 5, 4, 5,\n",
       "       4, 5, 2, 3, 0, 4, 7, 4, 0, 5, 4, 6, 2, 3, 0, 3, 6, 4, 4, 7, 6, 0,\n",
       "       7, 2, 7, 1, 0, 1, 6, 5, 1, 2, 7, 5, 7, 1, 7, 6, 5, 6, 1, 6, 2, 1,\n",
       "       1, 1, 0, 7, 0, 0, 2, 5, 7, 6, 4, 1, 6, 1, 2, 1, 0, 7, 4, 3, 1, 6,\n",
       "       0, 3, 4, 3, 0, 7, 7, 5, 7, 5, 3, 2, 6, 6, 3, 1, 1, 7, 6, 6, 5, 2,\n",
       "       0, 1, 6, 5, 4, 5, 1, 1, 5, 0, 3, 1, 5, 6, 5, 2, 3, 4, 0, 7, 4, 3,\n",
       "       3, 3, 4, 6, 3, 5, 4, 7, 3, 5, 6, 2, 6, 7, 3, 7, 4, 1, 3, 1, 5, 2,\n",
       "       0, 7, 6, 2, 3, 1, 6, 1, 4, 1, 4, 5, 6, 6, 0, 3, 4, 0, 1, 1, 0, 6,\n",
       "       1, 7, 5, 5, 7, 0, 7, 4, 4, 0, 7, 4, 6, 7, 6, 4, 5, 4, 6, 2, 3, 1,\n",
       "       7, 2, 4, 5, 0, 4, 5, 3, 4, 6, 0, 5, 5, 5, 3, 4, 3, 7, 1, 1, 7, 4,\n",
       "       6, 3, 0, 5, 5, 4, 6, 1, 1, 5, 4, 3, 1, 3, 6, 1, 1, 2, 1, 7, 0, 7,\n",
       "       4, 4, 3, 7, 7, 7, 6, 1, 0, 3, 7, 7, 2, 3, 7, 3, 1, 2, 3, 0, 0, 4,\n",
       "       2, 2, 4, 3, 2, 0, 0, 7, 1, 2, 3, 4, 4, 3, 6, 5, 1, 4, 2, 1, 2, 6,\n",
       "       0, 1, 7, 4, 1, 1, 1, 5, 1, 2, 0, 6, 3, 1, 4, 1, 4, 2, 4, 7, 3, 0,\n",
       "       4, 4, 0, 3, 1, 4, 0, 7, 7, 2, 0, 2, 7, 3, 1, 0, 6, 7, 7, 6, 5, 7,\n",
       "       4, 3, 0, 6, 4, 6, 0, 2, 0, 5, 0, 0, 5, 3, 7, 0, 5, 4, 2, 2, 0, 3,\n",
       "       3, 4, 0, 2, 3, 0, 6, 3, 5, 6, 7, 3, 2, 1, 6, 7, 4, 4, 2, 3, 0, 3,\n",
       "       2, 4, 3, 4, 6, 7, 0, 6, 4, 4, 1, 1, 6, 5, 6, 1, 4, 2, 6, 4, 2, 2,\n",
       "       1, 6, 3, 0, 1, 1, 3, 0, 4, 5, 6, 5, 4, 7, 1, 0, 1, 2, 1, 1, 4, 4,\n",
       "       4, 5, 2, 7, 7, 4, 0, 5, 3, 0, 6, 6, 0, 4, 3, 3, 5, 3, 6, 2, 4, 3,\n",
       "       5, 6, 2, 1, 1, 2, 6, 5, 2, 4, 4, 1, 3, 5, 1, 3, 3, 7, 4, 6, 0, 6,\n",
       "       0, 2, 4, 3, 5, 0, 6, 3, 0, 0, 7, 0, 5, 4, 5, 1, 3, 4, 7, 4, 4, 6,\n",
       "       4, 7, 5, 4, 2, 3, 4, 3, 2, 2, 3, 0, 1, 6, 0, 0, 5, 6, 6, 0, 4, 5,\n",
       "       5, 2, 7, 6, 0, 2, 3, 1, 7, 7, 7, 5, 3, 7, 3, 4, 7, 1, 3, 3, 1, 7,\n",
       "       1, 3, 1, 3, 3, 4, 0, 3, 7, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(7),\n",
       " array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1. , 1. , 1. , 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "np.argmax(y[i]), X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary codes for labels (8×3)\n",
    "binary_codes = torch.stack(\n",
    "    [torch.tensor([int(b) for b in format(i, \"03b\")]) for i in range(8)], dim=0\n",
    ")\n",
    "binary_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(1),\n",
       " array([0.5, 1. , 0. , 0. , 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "        0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], dtype=float32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 9\n",
    "np.argmax(y[i]), X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [0, 1, 0],\n",
      "        [1, 1, 0],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "binary_codes = torch.stack(\n",
    "    [torch.tensor([int(b) for b in format(i, \"03b\")]) for i in range(8)], dim=0\n",
    ").flip(-1)  # <-- reverse bit order in-place\n",
    "\n",
    "print(binary_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
